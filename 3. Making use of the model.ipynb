{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with the model\n",
    "Let's make a filter like snapchat's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of attach\n",
    "- Detect faces in an image\n",
    "- Cut the region of interest (ROI) with some padding\n",
    "- Feed the transformed ROI to the model and get the facial keypoints\n",
    "- select important keypoints (the eye keypoints in this example)\n",
    "- read the filter image (has to have an alpha chanel)\n",
    "- replace pixel data from the ROI with those of the filter\n",
    "- repaint the ROI on the main image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datagenerator import FacialKeyPointsDataset\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import tensorflowjs as tfjs\n",
    "%matplotlib inline\n",
    "\n",
    "TEST_IMG = \"images/test5.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect face\n",
    "We'll use openCV for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(image):\n",
    "    # load in a haar cascade classifier for detecting frontal faces\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        'detector_architectures/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # run the detector\n",
    "    faces = face_cascade.detectMultiScale(image, 1.2, 10, 30)\n",
    "\n",
    "    # make a copy of the original image to plot detections on\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    # loop over the detected faces, mark the image where each face is found\n",
    "    for (x, y, w, h) in faces:\n",
    "        # draw a rectangle around each detected face\n",
    "        cv2.putText(image_with_detections, 'Hooman', (x, y-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.rectangle(image_with_detections, (x, y),\n",
    "                      (x + w, y + h), (0, 0, 255), 3)\n",
    "\n",
    "    return image_with_detections, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(TEST_IMG)\n",
    "img_with_faces, faces = detectFace(img)\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_with_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut the region of interest\n",
    "simple array slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3*len(faces), 3*len(faces)))\n",
    "idx = 1\n",
    "for (x, y, h, w) in faces:\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    plt.subplot(1, len(faces), idx)\n",
    "    plt.imshow(roi)\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get keypoints\n",
    "We need to load the model first  \n",
    "We also need to create an instance of the data generator to get the transformers and the mean, std vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(\n",
    "    'models/model_vector_batchnorm_194.json',\n",
    "    'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\n",
    "    \"models/model_vector_batchnorm_194.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "datasetgen = FacialKeyPointsDataset(csv_file='data/training_frames_keypoints.csv',\n",
    "                                    root_dir='data/training/',\n",
    "                                    normalization=\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(frame, face):\n",
    "    # the padding, that guy has a huge chin that we need to be visible in the image\n",
    "    pad = 50\n",
    "    (x, y, w, h) = face\n",
    "    # get the region of interes, this time with padding\n",
    "    roi = frame[y - pad:y + h + pad, x - pad:x + w + pad]\n",
    "    # we'll need the original size to rescale the image back to it\n",
    "    originalSize = roi.shape\n",
    "    if(originalSize[0] == 0 or originalSize[1] == 0):\n",
    "        return (), roi, originalSize, (0, 0, 0, 0)\n",
    "    \n",
    "    roi = cv2.resize(roi, datasetgen.output_size)\n",
    "    \n",
    "    # preprocess the roi before prediction\n",
    "    img = datasetgen.preprocess_test(roi)\n",
    "    \n",
    "    # make a batch from the image\n",
    "    img = img.reshape(1, *img.shape, 1)\n",
    "    keypts = model.predict(img).reshape(-1, 1)\n",
    "    keypts = keypts * datasetgen.std + datasetgen.mean\n",
    "    keypts = keypts.reshape(-1, 2)\n",
    "\n",
    "    return keypts, roi, originalSize, (x-pad, y-pad, w+pad*2, h+pad*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(TEST_IMG)\n",
    "plt.figure(figsize=(4*len(faces), 4*len(faces)))\n",
    "idx = 1\n",
    "for face in faces:\n",
    "    keypts, roi, originalSize, padded = get_key_points(img, face)\n",
    "    plt.subplot(1, len(faces), idx)\n",
    "    plt.imshow(roi)\n",
    "    plt.scatter(keypts[:, 0], keypts[:, 1], marker=\".\", s=23, color=\"m\")\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/absolute_win.jpg\" /> \n",
    "### **Greate**\n",
    "now let's get to business  \n",
    "Of course if you train your model more than I did, or design a better architecture, you'll get better results\n",
    "### Selecting important keypoints\n",
    "Let's know the the index of the keypoint we want\n",
    "<img src=\"./images/landmarks_numbered.jpg\" width=\"400px\" />\n",
    "**NOTE**: These numbers start at 1, when we index them we'll start at 0 of course  \n",
    "In this notebook we're gonna add glasses to the faces so \n",
    "- we need to pick a point to be the top lefthand corner of the image, point 18 seems good  \n",
    "- We'll also need tow points to know the width we need to give the filter\n",
    "- and two more for the height\n",
    "- we could need to offset the origin of the filter\n",
    "- we could need to add padding to the filter as well  \n",
    "**OH!** I've got an idea, let's make a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter:\n",
    "    def __init__(self, path, coord, h_points, w_points, offset=(0, 0), padding=(0, 0)):\n",
    "        self.img = mpimg.imread(path, -1)\n",
    "        self.coord = coord\n",
    "        self.h_points = h_points\n",
    "        self.w_points = w_points\n",
    "        self.offset = offset\n",
    "        self.padding = padding\n",
    "        \n",
    "    def apply(self, keypts, roi):\n",
    "        \"\"\" Apply the filter given the keypts on the given frame\n",
    "        Args:\n",
    "            keypts: the keypoints array\n",
    "            roi: the face image to which you want to apply the filter\n",
    "        \"\"\"\n",
    "        w = int(abs(\n",
    "            keypts[ self.w_points[0] ][0] - keypts[ self.w_points[1] ][0]\n",
    "        )) + self.padding[0]\n",
    "\n",
    "        h = int(abs(\n",
    "            keypts[ self.h_points[0] ][1] - keypts[ self.h_points[1] ][1]\n",
    "        )) + self.padding[1]\n",
    "\n",
    "        filter_img = cv2.resize(self.img, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        x = int(keypts[self.coord][0]) + self.offset[0]\n",
    "        y = int(keypts[self.coord][1]) + self.offset[1]\n",
    "\n",
    "        roi_color = roi[y:y + h, x:x + w]\n",
    "\n",
    "        non_trans = np.argwhere(filter_img[:, :, 3] > 0)\n",
    "\n",
    "        if(non_trans.shape[0] > roi_color.shape[0]*roi_color.shape[1]):\n",
    "            return roi\n",
    "\n",
    "        roi_color[non_trans[:, 0], non_trans[:, 1],\n",
    "                  :3] = filter_img[non_trans[:, 0], non_trans[:, 1], :3]\n",
    "        roi[y:y + h, x:x + w] = roi_color\n",
    "        \n",
    "        return roi\n",
    "        \n",
    "\n",
    "filter1 = Filter(\n",
    "        path=\"images/filter1.png\",\n",
    "        coord=17,\n",
    "        h_points=(25, 29),\n",
    "        w_points=(2, 16),\n",
    "        offset=(-10, 0)\n",
    ")\n",
    "# define more if you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(TEST_IMG)\n",
    "plt.figure(figsize=(5, 5))\n",
    "idx = 1\n",
    "for face in faces:\n",
    "    keypts, roi, originalSize, padded = get_key_points(img, face)\n",
    "    plt.subplot(1, len(faces), idx)\n",
    "    plt.imshow(filter1.apply(keypts, roi))\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is greate.. \n",
    "Now let's put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = mpimg.imread(TEST_IMG).copy() # if you don't copy you'll get an immutable array and you don't want that\n",
    "\n",
    "# detect faces\n",
    "img_with_faces, faces = detectFace(img)\n",
    "\n",
    "# iterate over faces and get keypoints for each face\n",
    "for face in faces:\n",
    "    keypts, roi, originalSize, (x, y, w, h) = get_key_points(img, face)\n",
    "    roi = filter1.apply(keypts, roi)\n",
    "    roi = cv2.resize(roi, (originalSize[:2]))\n",
    "    img[y:y + h, x:x + w] = roi\n",
    "    \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greate\n",
    "If you've made it thus far, pat your self on the back, you will never be the same person again, you now know more  \n",
    "In this repo you will find the files that combine all of this to make a live filter  \n",
    "**Have Fun**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
